{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# What is the doggest dog?\n",
    "\n",
    "This is a notebook that can be used to perform experiments connected to our paper.\n",
    "\n",
    "The aim of our method is to determine prototypes and anti-prototypes for a given basic-level category. Our methods aim to examine deep learning models from the perspective of the Prototype Theory.\n",
    "\n",
    "Method from the paper: Strategy 3 (based on Multidimensional Scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the following function to find the hyponyms for a given basic-level category - hypernym:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_hyponyms(hypernym_name):\n",
    "    \"\"\"\n",
    "    Function ca be used to obtain a list of indexes of the ImageNet classes \n",
    "    belonging to a given basic-level category (a hypernym).\n",
    "    ------\n",
    "    Pramaters: \n",
    "    \n",
    "    hypernym_name: a desired hypernym (e.g. \"domestic_cat\")\n",
    "    \"\"\"\n",
    "    from nltk.corpus import wordnet as wn\n",
    "    import nltk\n",
    "    from tensorflow.keras.applications.imagenet_utils import decode_predictions\n",
    "    from tensorflow.keras.utils import to_categorical\n",
    "    import numpy as np\n",
    "    \n",
    "    hyponyms = wn.synsets(hypernym_name)[0]\n",
    "    hyponyms = set([i for i in hyponyms.closure(lambda s:s.hyponyms())])\n",
    "    offsets = []\n",
    "    imagenet_classes = decode_predictions(to_categorical(np.expand_dims(np.array(range(1000)), axis=-1), num_classes=1000), top=1)\n",
    "\n",
    "    for c in imagenet_classes:\n",
    "        offsets.append(int(c[0][0].split('n')[1]))\n",
    "    \n",
    "    ids = []\n",
    "    for idx, o in enumerate(offsets):\n",
    "        isadoggo = wn.synset_from_pos_and_offset('n', int(o))\n",
    "        if isadoggo in hyponyms:\n",
    "            ids.append(idx)\n",
    "    return np.array(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_prototype_antiprototype_with_MDS(weights, hyponym_classes, random_seed=None):\n",
    "    \"\"\"\n",
    "    Function can be used to find prototypes and anti-prototypes for a given basic-level category \n",
    "    for a given deep learning model. It is a single iteration of MDS.\n",
    "    ------\n",
    "    Parameters: \n",
    "    \n",
    "    weights: extracted weights of categories of interest (+ a central element obtained as \n",
    "    an element-wise avg of all weights)\n",
    "    hyponym_classes: indexes of hyponyms (ImageNet classes to be embedded).\n",
    "    random_state: number used for MDS initialization (of points in MDS' 2D space).\n",
    "    \"\"\"\n",
    "    from sklearn.manifold import MDS\n",
    "    from sklearn.metrics.pairwise import cosine_distances\n",
    "    from sklearn.metrics.pairwise import euclidean_distances\n",
    "    from tensorflow.keras.applications.imagenet_utils import decode_predictions\n",
    "    from tensorflow.keras.utils import to_categorical\n",
    "    \n",
    "    cosine_distances = cosine_distances(weights)\n",
    "    if random_seed is not None:\n",
    "        embedding = MDS(n_components=2, normalized_stress='auto', dissimilarity='precomputed', random_state=random_seed)\n",
    "    else:\n",
    "        embedding = MDS(n_components=2, normalized_stress='auto', dissimilarity='precomputed')\n",
    "    X_transformed = embedding.fit_transform(cosine_distances)\n",
    "    idx = hyponym_classes[np.argmin(euclidean_distances(np.expand_dims(X_transformed[-1], axis=0), X_transformed[:-2]))]\n",
    "    idx_distant = hyponym_classes[np.argmax(euclidean_distances(np.expand_dims(X_transformed[-1], axis=0), X_transformed[:-2]))]\n",
    "    prototype = decode_predictions(to_categorical([[idx]], num_classes=1000), top=1)[0][0][1]\n",
    "    antiprototype = decode_predictions(to_categorical([[idx_distant]], num_classes=1000), top=1)[0][0][1]\n",
    "    return prototype, antiprototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def return_prototype_antiprototype(model, hypernym_name, keras=True, levit=False, N_MDS=500, seeds=None):\n",
    "    \"\"\"\n",
    "    Function can be used to find prototypes and anti-prototypes for a given basic-level category \n",
    "    for a given deep learning model. \n",
    "    Parameters: \n",
    "    model: keras/torch model trained on ImageNet (with a standard order of classes that can be decoded with \n",
    "    tensorflow.keras.applications.imagenet_utils.decode_predictions\n",
    "    hypernym_name: string with a name of a basic-level category, e.g. \"domestic_cat\", \"dog\" etc.\n",
    "    high_level_category: in strategy 2, besides the hyponyms of our desired category, we also use\n",
    "    a contrasting category. A contrasting category is a complement of a set of some higher-level categories. \n",
    "    keras: flag whether we want to use a keras model (set True if yes - it is a default). \n",
    "    Set false in the case of using a torch model.\n",
    "    levit: set with keras=False in the case of using one of the LeViTs models.\n",
    "    N_MDS: number of MDS algorithms runs to find a prototype and anti-prototype\n",
    "    seeds: a numpy array of seeds (with length N_MDS) to generate \n",
    "    the results (use numpy.random.randint(0, 5000, size=500) \n",
    "    with numpy.random.seed(55) for the reproduction of results.\n",
    "    Alternatively, one can used the already generated list of numbers\n",
    "    from file random_nums.txt (generated this way). \n",
    "    \"\"\"\n",
    "    from tensorflow.keras.applications.imagenet_utils import decode_predictions\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "    \n",
    "    hyponym_classes = find_hyponyms(hypernym_name=hypernym_name)    \n",
    "    print(f\"Members of the basic-level category (for hypernym = {hypernym_name}):\")\n",
    "    print(len(hyponym_classes))\n",
    "    \n",
    "    # Extraction of weights (we consider models from Keras Application (https://keras.io/api/applications/)\n",
    "    # and HuggingFace (https://huggingface.co/models) listed in the provided file Model_List.pdf\n",
    "    if keras:\n",
    "        hyponym_weights = np.moveaxis(model.layers[-1].get_weights()[0][:, hyponym_classes], -1, 0)\n",
    "        hypernym_weights = np.mean(model.layers[-1].get_weights()[0][:, hyponym_classes], axis=1)\n",
    "        hypernym_weights = np.expand_dims(hypernym_weights, axis=0)\n",
    "        all_weights = np.concatenate([hyponym_weights, hypernym_weights], axis=0)\n",
    "    else:\n",
    "        if not levit:\n",
    "            hyponym_weights = model.classifier.weight.detach().numpy()[hyponym_classes, :]\n",
    "            hypernym_weights = np.mean(hyponym_weights, axis=0)\n",
    "            hypernym_weights = np.expand_dims(hypernym_weights, axis=0)\n",
    "            all_weights = np.concatenate([hyponym_weights, hypernym_weights], axis=0)\n",
    "        else:\n",
    "            # models from the LeViT family have slightly different model structure than the other models \n",
    "            # from HuggingFace\n",
    "            hyponym_weights = model.classifier_distill.linear.weight.detach().numpy()[hyponym_classes, :]\n",
    "            hypernym_weights = np.mean(hyponym_weights, axis=0)\n",
    "            hypernym_weights = np.expand_dims(hypernym_weights, axis=0)\n",
    "            all_weights = np.concatenate([hyponym_weights, hypernym_weights], axis=0)\n",
    "            \n",
    "    # Running MDS for 500 times to find prototypes and anti-types\n",
    "\n",
    "    potential_prototypes = []\n",
    "    potential_antiprototypes = []\n",
    "    for i in range(N_MDS):\n",
    "        if seeds is not None and len(seeds) == (N_MDS):\n",
    "            maxx, minn = determine_prototype_antiprototype_with_MDS(all_weights, hyponym_classes, seeds[i])\n",
    "        else:\n",
    "            maxx, minn = determine_prototype_antiprototype_with_MDS(all_weights, hyponym_classes)\n",
    "        potential_prototypes.append(maxx)\n",
    "        potential_antiprototypes.append(minn)\n",
    "        \n",
    "    prototype = max(set(potential_prototypes), key = potential_prototypes.count)\n",
    "    antiprototype = max(set(potential_antiprototypes), key = potential_antiprototypes.count)\n",
    "    print(\"prototype\")\n",
    "    print(prototype)\n",
    "    print(\"anti-prototype\")\n",
    "    print(antiprototype)\n",
    "    return prototype, antiprototype "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below one needs to set a WordNet node name - a desired basic-level category.\n",
    "\n",
    "**In our experiments, we use the following nodes:**\n",
    "\n",
    "Natural categories:\n",
    "\n",
    "* *domestic_cat*\n",
    "* *dog*\n",
    "* *bird*\n",
    "* *fish*\n",
    "* *mammal*\n",
    "\n",
    "Artificial category: *musical_instrument*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hypernym_name = \"domestic_cat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example (in our experiments for the purpose of our paper, we use N_MDS=500, and seeds generated\n",
    "# via numpy.random.randint(0, 5000, size=500) with numpy.random.seed(55)\n",
    "N_MDS = 3\n",
    "seeds = np.array([4557, 4762, 4391])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example for keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inception_v3\n",
      "Members of the basic-level category (for hypernym = domestic_cat):\n",
      "5\n",
      "prototype\n",
      "tabby\n",
      "anti-prototype\n",
      "Siamese_cat\n"
     ]
    }
   ],
   "source": [
    "# generating results for different CNNs (keras)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "model = tf.keras.applications.InceptionV3(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    pooling='avg',\n",
    "    classes=1000,\n",
    "    classifier_activation=\"softmax\"\n",
    ")\n",
    "\n",
    "print(model.name)\n",
    "most_similar, least_similar = return_prototype_antiprototype(model=model, N_MDS=N_MDS, seeds=seeds,  \n",
    "                                                        hypernym_name=hypernym_name, \n",
    "                                                        keras=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example for torch models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "microsoft/swinv2-tiny-patch4-window8-256\n",
      "Members of the basic-level category (for hypernym = domestic_cat):\n",
      "5\n",
      "prototype\n",
      "tabby\n",
      "anti-prototype\n",
      "Siamese_cat\n",
      "LevitForImageClassificationWithTeacher\n",
      "Members of the basic-level category (for hypernym = domestic_cat):\n",
      "5\n",
      "prototype\n",
      "tabby\n",
      "anti-prototype\n",
      "Siamese_cat\n"
     ]
    }
   ],
   "source": [
    "# generating results for different transformers (pytorch) - standard + example LeViT\n",
    "\n",
    "from transformers import AutoModelForImageClassification\n",
    "\n",
    "name = \"microsoft/swinv2-tiny-patch4-window8-256\"\n",
    "model = AutoModelForImageClassification.from_pretrained(name)\n",
    "\n",
    "print(name)\n",
    "most_similar, least_similar = return_prototype_antiprototype(model=model, N_MDS=N_MDS, seeds=seeds,  \n",
    "                                                        hypernym_name=hypernym_name, \n",
    "                                                        keras=False)\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "name = 'facebook/levit-384'\n",
    "model = AutoModelForImageClassification.from_pretrained(name)\n",
    "\n",
    "print(model.__class__.__name__)\n",
    "most_similar, least_similar = return_prototype_antiprototype(model=model, N_MDS=N_MDS, seeds=seeds,  \n",
    "                                                        hypernym_name=hypernym_name, \n",
    "                                                        keras=False, levit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
